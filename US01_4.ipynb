{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US01 - 4 \n",
    "## Python\n",
    "### Game of thrones part 2\n",
    "\n",
    "Know, we have our first graph. But there is some problem. For example we have 'Waymar Royce', 'Royce', 'Ser Waymar' and 'Waymar' , there are all the same person. We need to find a way to regroup them.\n",
    "\n",
    "1. Similarity in graph \n",
    "2. Word2vec (gensim) similiarities\n",
    "3. Ask for the list of characters and compare with our\n",
    "    We can find one here: https://awoiaf.westeros.org/index.php/List_of_characters \n",
    "  \n",
    "**1. Lemmatize**\n",
    "\n",
    "We will to use the third way. We need to lemmatize (lemma: there most complete version of the word, here the name). We call an API and clean the data (we use BeautifulSoup to get the information we want) to get the list of characters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://awoiaf.westeros.org/index.php/List_of_characters'\n",
    "r = requests.get(url)\n",
    "\n",
    "text = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the pages is 2118\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(text, 'lxml')\n",
    "\n",
    "links = soup.find_all('a') # <a href='url'>text<\\a>\n",
    "\n",
    "#our array for the page which mention a characters\n",
    "pages = []\n",
    "\n",
    "for link in links:\n",
    "    what_we_want = set(['title', 'href'])\n",
    "    what_there_is = set(link.attrs.keys())\n",
    "    # take only the link for a characters (which have exactly title and href for attribues)\n",
    "    if what_we_want == what_there_is:\n",
    "        # we make tuples in an array\n",
    "        pages.append((link['href'],link['href'].split('/')[-1]))\n",
    "        \n",
    "# we have to remove the last 5\n",
    "pages = pages[:-5]\n",
    "#remove the duplicate\n",
    "pages = set(pages)\n",
    "print('length of the pages is', len(pages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is pages 2126 to download. It's will take around 3h. Download during 3h is tricky in China. So we need to download one by one and if something go wrong, start again where the script stop. Here, we just try with one page: Aegon V Targaryen, because it'll be to long otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/index.php/Aegon_V_Targaryen\n"
     ]
    }
   ],
   "source": [
    "for href, name in pages: \n",
    "    if name =='Aegon_V_Targaryen':\n",
    "        print(href)\n",
    "        r = requests.get('https://awoiaf.westeros.org' + href)\n",
    "        with open(name+'.html', 'w+', encoding = 'utf-8') as fp:\n",
    "            fp.write(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the page about Aegon V Targaryen. We need to find the name, the surname, the full name... This information are in the *infobox* (the box in the right like wikipedia). Here, the information of the infobox are in the *tbody*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aegon V'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Aegon_V_Targaryen.html', 'r', encoding = 'utf-8') as fp: \n",
    "    html = fp.read()\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "soup.find(\"table\", class_=\"infobox\").b.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all the tbody (info in the infobox)\n",
    "tbody = soup.find(\"table\", class_=\"infobox\").tbody\n",
    "\n",
    "# take all the row in the tbody \n",
    "rows = tbody.find_all(\"tr\")\n",
    "\n",
    "# parcours the tree\n",
    "# parcours all the tr, tr contains td or th and td\n",
    "for row in rows:\n",
    "    # so the child of row (tr) are td or th\n",
    "    for child in row.children: \n",
    "        if child.name =='th': #here, th = full name, td = the name\n",
    "            if row.th.text == 'Full Name': # get the td (the name)\n",
    "                name = row.td.text\n",
    "            if row.th.text == 'Alias': # get the td (the name)\n",
    "                alias = row.td.text    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem is that our alias are stick with each other (Lower casse follow by Upper casse). We use a regular expression to modify (try on https://regex101.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aegon the Unlikely, Aegon the Fortunate, Egg, The Prince Who Was An Egg\n",
      "['Aegon the Unlikely', 'Aegon the Fortunate', 'Egg', 'The Prince Who Was An Egg']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#if a lower casse letter is immediately follow by a upper casse letter\n",
    "regex = r\"([a-z])([A-Z])\"\n",
    "subst = \"\\\\1, \\\\2\"\n",
    "\n",
    "result = re.sub(regex, subst, alias)\n",
    "print(result)\n",
    "\n",
    "#put the data in a array, ready to be used\n",
    "print([t.strip() for t in result.split(',')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Know we are trying to get the list of books where the characters appears and clean the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The World of Ice & Fire (mentioned)The Hedge Knight (appears)The Sworn Sword (appears)The Mystery Knight (appears)A Game of Thrones (mentioned)A Clash of Kings (mentioned)A Storm of Swords (mentioned)A Feast for Crows (mentioned)A Dance with Dragons (mentioned)\n",
      "\n",
      "The World of Ice & Fire ,The Hedge Knight ,The Sworn Sword ,The Mystery Knight ,A Game of Thrones ,A Clash of Kings ,A Storm of Swords ,A Feast for Crows ,A Dance with Dragons ,\n",
      "['The World of Ice & Fire', 'The Hedge Knight', 'The Sworn Sword', 'The Mystery Knight', 'A Game of Thrones', 'A Clash of Kings', 'A Storm of Swords', 'A Feast for Crows', 'A Dance with Dragons', '']\n"
     ]
    }
   ],
   "source": [
    "for row in rows:\n",
    "    for child in row.children: \n",
    "        if child.name =='th': \n",
    "            if row.th.text == 'Books': \n",
    "                books = row.td.text\n",
    "print(books)\n",
    "\n",
    "#delete the \"()\" and split the data \n",
    "import re\n",
    "\n",
    "regex = r\"\\([a-zA-Z]+\\)\"\n",
    "subst = \",\"\n",
    "\n",
    "result = re.sub(regex, subst, books)\n",
    "print(result)\n",
    "\n",
    "#put the data in a array, ready to be used\n",
    "print([t.strip() for t in result.split(',')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *The problem is there is a space before the \"(\" so we can split one the lowercasse follow by the uppercasse. So I put a ',' to split and consequently I have a empty book at the end...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
